---
title: "Uniform test cases"
output: html_notebook
---

```{r}
source("augmented_utils.R")
```


```{r}
registerDoParallel(cores = 20)


pp = transport::pp
```


```{r}
CtoR = function(clusts, only_bornes = TRUE, n_sample = NULL){
  return(list(try_unif(clusts, only_bornes, n_sample), as.list(rep("unif",length(clusts)))))
}


```

## Simple test case

We introduce the sample representing the mixture $R_{J}$ with 

- $R_{1} = \mathcal{U}(0.3,0.6)$
- $R_{2} = \mathcal{U}(0,1)$
- $P(J=1) = \frac{2}{3}$
- $P(J=2) = \frac{1}{3}$

```{r}
set.seed(4)

samp_unif1d = matrix(c(sobol(200)*0.3+0.3, sobol((10^5+1):(10^5+100))))

plot_sample(clusts = list(samp_unif1d[1:200,], samp_unif1d[201:300,]), rpz = c("U(0.3,0.6)", "U(0.3,0.6) "))


```

We try one iteration of the algorithm, starting from $R_{1} = \mathcal{U}(0,0.5)$ and $R_{2} = \mathcal{U}(0.5,1)$


```{r}
set.seed(10,"L'Ecuyer-CMRG")
rep = list(matrix(c(0,0.5)), matrix(c(0.5,1))) #initial representatives

res_find_clusts = find_c(samp = samp_unif1d, rep = rep,weights = c(0.5,0.5),law = as.list(c("unif","unif"))) #find_clusters

clusts = lapply(res_find_clusts[[1]], function(x){matrix(x,ncol = ncol(rep[[1]]))})

nums = res_find_clusts[[2]]
num_throw = lapply(1:2, function(i){f_delete(clusts[[i]], n = 0.4*nrow(clusts[[i]]), n_sample = 1000)})

clusts_throw = lapply(1:2, function(i){matrix(clusts[[i]][num_throw[[i]],], ncol = ncol(samp_unif1d))})

clusts_split = lapply(1:2, function(i){matrix(clusts[[i]][-num_throw[[i]],], ncol = ncol(samp_unif1d))})

clusts_split = c(clusts_split, clusts_throw) #split

merge = merge_clusts(clusts_split, length(rep), n_sample = 1000) #merge

new_clusts = merge[[2]]
rep = merge[[1]][[1]]
error = merge[[4]]

plot_clusts(clusts) #plot the initial clusts
plot_clusts(clusts_split) +  scale_fill_discrete(labels = c("1", "2", "1bin","2bin")) + guides(color = FALSE) #plot the split clusters
plot_clusts(new_clusts) #plot the merged clusters
rep
```

## No perturb 

We try to run the augmented quantization algorithm without the perturbation

```{r}
registerDoParallel(cores = 10)

set.seed(10,"L'Ecuyer-CMRG")

rep = list(matrix(c(0,0.5)), matrix(c(0.5,1)))
# 
res_unif_1d = augmented_quanti(samp = samp_unif1d, rep = rep, perturb_bool = FALSE, vec_prop = c(10), it_lim = 10, law = as.list(rep("unif",2))) 
```

```{r}
reps = lapply(1:2,function(k){matrix(runif(10^6, res_unif_1d[[2]][[10]][[4]][[1]][[k]][1,1], res_unif_1d[[2]][[10]][[4]][[1]][[k]][2,1]))})

weights = Vectorize(function(j){nrow(res_unif_1d[[2]][[10]][[3]][[j]])/sum(sapply(res_unif_1d[[2]][[10]][[3]], nrow))})(1:length(res_unif_1d[[2]][[10]][[3]]))
error_quanti = sqrt(weighted.mean(local_errors(res_unif_1d[[2]][[10]][[3]], reps, 1:2)^2, weights))
```

```{r}
for(i in 1:10){
  print(plot_clusts(res_unif_1d[[2]][[i]][[3]]))
}
```

## With perturb 

```{r}
set.seed(10,"L'Ecuyer-CMRG")

rep = list(matrix(c(0,0.5)), matrix(c(0.5,1)))
# 
res_unif_1d = augmented_quanti(samp = samp_unif1d, rep = rep,vec_prop = c(0.4,0.3,0.2,0.1,0.05,0.025), it_lim = 10,n_sample = 1000,threshold = 0.02, law = as.list(rep("unif",2)))
# 
best_unif_1d = find_best(res_unif_1d)

df_plot = create_df_plot(list(best_unif_1d[[4]][[1]][[2]],best_unif_1d[[4]][[1]][[1]]),list(best_unif_1d[[3]][[2]], best_unif_1d[[3]][[1]]))
plot_hybrid_distrib(df_plot,c("X1"))


plot_clusts(clusts = list(best_unif_1d[[3]][[2]],best_unif_1d[[3]][[1]]))
#save(res_unif_1d, file = "res_unif_1d.RData")
```

```{r}
best_unif_1d[[4]]
sapply(best_unif_1d[[3]],nrow)/300
```


```{r}
set.seed(1000)

best_mixture_unif1d = get_mixture(rep = best_unif_1d[[4]][[1]], clusts = best_unif_1d[[3]], law = as.list(c("unif","unif")), n=10^6) 

true_mixture_unif1d = get_mixture(list(matrix(c(0.3,0.6)), matrix(c(0,1))), weights = c(2/3,1/3), law = as.list(c("unif","unif")), n=10^6)

print(paste("Wasserstein distance with augmented algorithm ",wasserstein1d(best_mixture_unif1d, samp_unif1d,p=2)))
print(paste("Wasserstein distance with true mixture ",wasserstein1d(true_mixture_unif1d, samp_unif1d,p=2)))


reps = lapply(1:2,function(k){matrix(runif(10^6, best_unif_1d[[4]][[1]][[k]][1,1], best_unif_1d[[4]][[1]][[k]][2,1]))})

weights = Vectorize(function(j){nrow(best_unif_1d[[3]][[j]])/sum(sapply(best_unif_1d[[3]], nrow))})(1:length(best_unif_1d[[3]]))
error_quanti = sqrt(weighted.mean(local_errors(best_unif_1d[[3]], reps, 1:2)^2, weights))

print(paste("Quantization error obtained with augmented algorithm ",error_quanti))

reps_true = list(matrix(runif(10^6, 0.3, 0.6)),matrix(runif(10^6, 0, 1)))
weights_true = c(2/3,1/3)
error_quanti_true = sqrt(weighted.mean(local_errors(list(samp_unif1d[1:200,], samp_unif1d[201:300,]), reps_true, 1:2)^2, weights_true))

print(paste("Quantization error obtained with true mixture ",error_quanti_true))

```

## Tests other samples

We create 15 other samples

```{r}
RNGkind("default")
set.seed(12345)
list_sampunif = list()
df_params = data.frame()
error_true = c()
for(i in 1:15){
  params = sort(runif(4))
  a = params[1] #Lower bound of the first uniform
  c = params[2] #Lower bound of the second uniform
  borne_2 = sample(c(params[3],params[4]), size = 2)
  b = borne_2[1] #Upper bound of the first uniform
  d = borne_2[2] #Lower bound of the second uniform
  weights = runif(1,0.2,0.8) #Weights
  weights = round(c(weights, 1-weights),2)
  lengths = as.integer(round(weights*300)) #lengths of the sample of each uniform
  list_sampunif[[i]] = matrix(c(sobol(lengths[1])*(b-a)+a, sobol((10^5+1):(10^5+lengths[2]))*(d-c)+c)) #generation of the sample
  df_params = rbind(df_params, c(a,b,c,d, lengths)) #store the parameters
  reps_true = list(matrix(runif(10^6, a, b)), matrix(runif(10^6, c, d)))
  clusts_true = list(matrix(list_sampunif[[i]][1:lengths[1],]), matrix(list_sampunif[[i]][(lengths[1]+1):length(list_sampunif[[i]]),]))
  error_true = c(error_true,sqrt(weighted.mean(local_errors(clusts_true, reps_true, 1:2)^2, weights)) ) #computation of the true quantization error
}

```

We perform the Augmented Quantization method on each of the 30 samples

```{r, echo = FALSE}
nbstart = 3 #We will perform the method with 3 starts
list_record_mixtures = as.list(rep(0,30))
for(i in 1:15){
  print(paste("SAMPLE NUMERO ",i))
  print(paste("TRUE ERROR", error_true[i]))
  err = 10^5
  set.seed(i*9,"L'Ecuyer-CMRG")
  params_list = lapply(1:nbstart, function(k){c(sort(runif(2)), sort(runif(2)))}) #We generate the intitial representatives for each of the 3 starts
  for(k in 1:nbstart){
    params = params_list[[k]]
    rep = list(matrix(c(params[1],params[2])), matrix(c(params[3],params[4]))) 
    res_unif_1d = augmented_quanti(list_sampunif[[i]], rep, vec_prop = c(0.4,0.2,0.1,0.05), it_lim = 5,n_sample = 1000, find_c_bool = TRUE, law = as.list(rep("unif",2)))
    best = find_best(res_unif_1d)
    print(sqrt(best[[5]]))
    if(best[[5]]<err){
       list_record_mixtures[[i]] = res_unif_1d
       err = best[[5]]
    }
  }
}

```

We compute the global and quantization errors for each of the sample

```{r}
RNGkind("default")
set.seed(10)

error_aug = c()
wass_aug = c()
wass_true = c()
for(i in 1:15){
  print(i)
  best = find_best(list_record_mixtures[[i]])
  a = as.numeric(df_params[i,1])
  b=as.numeric(df_params[i,2])
  c = as.numeric(df_params[i,3])
  d = as.numeric(df_params[i,4])
  
  lengths_true = as.numeric(df_params[i,5:6])
  
  clusts = best[[3]]
  weights = Vectorize(function(j){nrow(clusts[[j]])/sum(sapply(clusts, nrow))})(1:length(clusts))
  #best[[4]] = CtoR(clusts = clusts, law = as.list(c("unif","unif")))

  reps = lapply(1:2,function(k){matrix(runif(10^6, best[[4]][[1]][[k]][1,1], best[[4]][[1]][[k]][2,1]))})
  error_aug = c(error_aug, sqrt(weighted.mean(local_errors(clusts, reps, 1:2)^2, weights)))

  mixture = get_mixture(rep = best[[4]][[1]], clusts = best[[3]],law = as.list(c("unif","unif")),n = 10^6)
  wass_aug = c(wass_aug, wasserstein1d(mixture, list_sampunif[[i]],p=2))
  
  mixt_true = get_mixture(rep = list(matrix(as.numeric(df_params[i, 1:2])), matrix(as.numeric(df_params[i, 3:4]))), weights = as.numeric(df_params[i, 5:6])/nrow(list_sampunif[[i]]), law = as.list(c("unif","unif")), n=10^6)
  wass_true = c(wass_true, wasserstein1d(mixt_true, list_sampunif[[i]],p=2))
}


```

We plot the distributions of these errors 

```{r}
df_errors = data.frame(rbind(cbind(error_aug,2),cbind(error_true,1), cbind(wass_true,3),cbind(wass_aug,4)))
colnames(df_errors) = c("Error","type")
df_errors$type = as.factor(df_errors$type)

df_errors = data.frame(rbind(cbind(wass_true,3),cbind(wass_aug,4), cbind(error_aug,2), cbind(error_true,1)))
colnames(df_errors) = c("Error","type")
df_errors$type = as.factor(df_errors$type)


ggplot(df_errors[df_errors$type %in% c('1','2'),], aes(x = type, y = Error, col = type)) + geom_boxplot() + theme_bw() + scale_color_discrete(name = "Quantization error", labels = c("True", "Augmented")) + theme(legend.position="top") + theme(legend.position="top",legend.text = element_text(size=15), legend.title = element_text("size" = 15))
ggplot(df_errors[df_errors$type %in% c('3','4'),], aes(x = type, y = Error, col = type)) + geom_boxplot() + theme_bw() + scale_color_discrete(name = "Global error", labels = c("True","Augmented")) +  theme(legend.position="top",legend.text = element_text(size=15), legend.title = element_text("size" = 15))

```

We plot the evolution of the errors through the iterations

```{r}

df_plot_err = data.frame()
for(i in 1:15){
  err = get_evol_error(list_record_mixtures[[i]])
  df_plot_err = rbind(df_plot_err, cbind(1:length(err),err, col = i))
}
df_plot_err$col = as.factor(df_plot_err$col)

ggplot(df_plot_err)+ geom_line(aes(x = V1, y = err,col = col))  +   theme_bw()+ theme(legend.position = "none") +  scale_y_continuous(trans='log10')


```
