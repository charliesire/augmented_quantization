---
title: "Dirac test cases"
output: html_notebook
---

```{r}
library(gridExtra)
```

For the dirac case, the Wasserstein distance is easier to compute so we will adapt the functions.

```{r}

dist2 = function(s1,s2){return(sqrt(sum((s1 - s2)^2)))} 

dist_dirac = function(clust, dirac){
  return(sqrt(mean(apply(clust, 1, function(x){dist2(x, dirac)^2}))))
} #Wasserstein distance between a cluster and a dirac distribution

distance_to_rep = function(x, rep){
  distance = Vectorize(function(k){dist2(x, rep[[k]])})(1:length(rep))
  return(list(cellule = which.min(distance), dist = min(distance)))
} #return the distance to the closest representative and the number of the associated representative

get_cell_numbers = function(samp, rep){
  return(Vectorize(function(it){distance_to_rep(x = samp[it,], rep = rep)$cellule})(1:nrow(samp)))
} #give the number of the representative associated to each element of the sample

find_clusters_dirac = function(samp, rep){
  nums = get_cell_numbers(samp, rep)
  samp_clust = lapply(1:max(nums), function(x){matrix(samp[nums == x,], nrow = sum(nums==x))})
  errors = sapply(1:length(samp_clust), function(x){dist_dirac(samp_clust[[x]], rep[[x]])})
  error_tot = weighted.mean(errors^2, sapply(samp_clust, nrow))
  return(list(clusters = samp_clust,nums = nums, error = error_tot, errors = errors))
} #find clusters


find_r = function(clust){
  return(matrix(apply(clust,2, mean),ncol=2))
} #find representative


f_delete_dirac = function(clust, dirac, n){ #split function
  df_res = c()
  nums = 1:length(clust)
  nb_col = ncol(clust)
  clust_init = clust
  while(length(df_res) < n & nrow(clust)>1){
    diff = Vectorize(function(j){
      error1 = dist_dirac(matrix(clust[-j,], ncol = nb_col), find_r(matrix(clust[-j,], ncol = nb_col)))
      error2 = dist_dirac(matrix(clust_init[c(df_res, nums[j]),], ncol = nb_col),  find_r(matrix(clust_init[c(df_res, nums[j]),], ncol = nb_col)))
      return(weighted.mean(c(error1,error2)^2, c(nrow(clust)-1, length(df_res)+1)))})(1:nrow(clust))
    clust = matrix(clust[-which.min(diff),], ncol = nb_col)
    df_res = c(df_res, nums[which.min(diff)])
    nums = nums[nums != nums[which.min(diff)]]
  }
  return(df_res)
} 



evol = function(former_rep, rep, threshold= 0){
  res = TRUE
  perms = permutations(length(rep), length(rep))
  for(i in 1:nrow(perms)){
    former_prov = lapply(1:length(former_rep), function(x){former_rep[[perms[i,x]]]})
    if(sum(Vectorize(function(x){dist2(former_prov[[x]], rep[[x]])})(1:length(rep))) <= threshold){return(FALSE)}
  }
  return(res)
}

merge_clusts_dirac = function(clusts){
  best_error = 10^5
  for(nb_1 in 1:(length(clusts)-1)){
      cbn = combinations(length(clusts), nb_1)
      for(i in 1:nrow(cbn)){
        clusts_tilde = list(do.call("rbind",lapply(cbn[i,], function(j){clusts[[j]]})), do.call("rbind",lapply(setdiff(1:length(clusts),cbn[i,]), function(j){clusts[[j]]})))
        rep_tilde = lapply(clusts_tilde, find_r)
        errors = sapply(1:length(rep_tilde), function(k){dist_dirac(clusts_tilde[[k]], rep_tilde[[k]])})
        error = weighted.mean(errors^2, sapply(clusts_tilde, nrow))
        if(error < best_error){
          best_error = error
          best_law = rep_tilde
          best_clusts = clusts_tilde
          best_merge = cbn[i,]
        }
      }
  }
  return(list(best_law, best_clusts, best_merge))
}

merge_clusts = function(clusts, l, law = NULL, n_sample = 500){
  eg <- expand.grid(rep(list(1:length(clusts)), l))
  eg = t(apply(eg, 1, sort))
  eg = unique(eg[which(rowSums(eg)==length(clusts)),])
  best_error = 10^5
  d = ncol(clusts[[1]])
  it = 0
  rec = list()
  for(row in 1:nrow(eg)){
    indexes = arrange_possibilities(eg[row,])
    rec[[row]] = indexes
    for(i in 1:length(indexes)){
      clusts_tilde = lapply(1:length(indexes[[i]]), function(x){do.call("rbind", lapply(indexes[[i]][[x]], function(j){clusts[[j]]}))})
      rep_tilde = lapply(clusts_tilde, find_r)
      errors = sapply(1:length(rep_tilde), function(k){dist_dirac(clusts_tilde[[k]], rep_tilde[[k]])})
      error = weighted.mean(errors^2, sapply(clusts_tilde, nrow))
      it=it+1
      if(error < best_error){
        best_error = error
        best_law = rep
        best_clusts = clusts_tilde
        best_merge = indexes[[i]]
      }
    }
  }
  return(list(best_law, best_clusts, best_merge, best_error))
}
```

We define the quantization error

```{r}
error_quanti = function(samp, rep){
  df = rep(0, nrow(samp))
  for(i in 1:nrow(rep)){
    df = cbind(df, Vectorize(function(j){dist2(samp[j,], rep[i,])^2})(1:nrow(samp)))
  }
  df = matrix(df[,2:ncol(df)], ncol = ncol(df) -1)
  nums = apply(df, 1, which.min)
  dists = Vectorize(function(k){df[k, nums[k]]})(1:nrow(df))
  return(sqrt(mean(dists)))
}
```

```{r}
augmented_quanti_dirac = function(samp, rep, n_sample = 500, l_bin =2, vec_prop = c(0.4,0.3,0.2,0.1,0.05,0.025),it_lim = 10, threshold = 0){
  record = list()
  for(pbin in vec_prop){
    for(it in 1:it_lim){
      clusts = find_clusters_dirac(samp, rep)[[1]] #get clusters
      k=1
      former_rep = rep 
      num_throw = lapply(1:length(clusts), function(i){f_delete_dirac(clusts[[i]], rep[[i]], n= pbin*nrow(clusts[[i]]))}) 
      clusts_throw = lapply(1:length(clusts), function(i){matrix(clusts[[i]][num_throw[[i]],], ncol = ncol(clusts[[i]]))})
      clusts_split = c(lapply(which(sapply(num_throw, function(x){!is.null(x)})), function(i){clusts[[i]][-num_throw[[i]],]}), lapply(which(sapply(num_throw, is.null)), function(i){clusts[[i]]}))
      clusts_split = c(clusts_split, clusts_throw)
      clusts_split = lapply(clusts_split, function(x){matrix(x,ncol=2)})
      clusts_split = clusts_split[sapply(clusts_split, function(x){nrow(x)>0})]
      former_rep = rep
      merge = merge_clusts_dirac(clusts_split)
      rep = merge[[1]]
      clusts = merge[[2]]
      #record <<- record
      k=k+1
      if(evol(former_rep, rep, threshold = 0) == F){break}
    }
    #print(rep)
    #record <<- record
  }
  return(list(rep,clusts))
}
```

Now we will compare the quantization error obtained with augmented quantization and with kmeans, with 2 representatives, with 20 starts for each sample 

```{r}
study_diff = function(samp_dir){ #samp_dir is a sample of point
  list_diracs = list() 
  list_kmeans = list()
  c_start = 1:20 #we will perform 20 starts
for(start in 1:length(c_start)){ #for each start
  set.seed(c_start[start])
  #if(start%%30 == 0){print(c_start[start])}
  idxs = sample(1:nrow(samp_dir),2)
  rep = list(matrix(samp_dir[idxs[1],],ncol=2), matrix(samp_dir[idxs[2],], ncol=2)) #the 2 starting representatives
  list_diracs[[start]] = augmented_quanti_dirac(samp_dir, rep) #output of augmented quanti
  list_kmeans[[start]] =  kmeans(samp_dir,centers = samp_dir[idxs,], algorithm = "Lloyd",iter.max = 100) #output of kmeans
}
  centroids_list = lapply(list_diracs, function(x){rbind(x[[1]][[1]], x[[1]][[2]])[order(c(x[[1]][[1]][1],x[[1]][[2]][1])),]})
  centroids_list_kmeans = lapply(list_kmeans, function(x){x$centers[order(x$centers[,1]),]})
                  
  error_1 = Vectorize(function(i){error_quanti(samp_dir, centroids_list[[i]])})(1:length(c_start)) #quantization error of augmented quanti
  error_2 = Vectorize(function(i){error_quanti(samp_dir, centroids_list_kmeans[[i]])})(1:length(c_start)) #quantization error of kmeans
  diff_error = (error_1-error_2)/error_2 #relative difference between the 2
  return(diff_error)
}
```


The comparison is performed on 500 samples

```{r}
list_diff = list()
for(seed in 1:500){
  if(seed %% 40== 0){print(seed)}
  set.seed(seed)
  samp_dir = cbind(runif(20), runif(20))
  list_diff[[seed]] = study_diff(samp_dir)
}

hist_err = unlist(list_diff)*100
```

We plot the distribution of the obtained relative differences

```{r}
ggplot(data.frame(x = hist_err), aes(x=x)) + geom_histogram(aes(x=x), binwidth = 2) + theme_bw() + xlab("Relative difference (in %)") + ylab("Number of tests")

sum(hist_err ==0)/length(hist_err)
sum(hist_err <0)/length(hist_err)
sum(hist_err >0)/length(hist_err)

median(-hist_err[hist_err < 0])
quantile(-hist_err[hist_err < 0],0.75)

```

We focus on an illustrative example

```{r}
set.seed(19)
samp_dir = cbind(runif(20), runif(20)) #illustrative sample

set.seed(18)
idxs = sample(1:nrow(samp_dir),2) 
rep = list(matrix(samp_dir[idxs[1],],ncol=2), matrix(samp_dir[idxs[2],], ncol=2)) #starting representatives
kk1 = augmented_quanti_dirac(samp_dir, rep) #output of augmented quanti
centro1 = data.frame(do.call("rbind",kk1[[1]])) #centroids of augmented quanti
kk2 = kmeans(samp_dir,centers = samp_dir[idxs,], algorithm = "Lloyd",iter.max = 100) #output of kmeans
centro2 = data.frame(kk2$centers) #centroids of kmeans
clusts1 = lapply(kk1[[2]], function(x){x[order(x[,1]),]}) #clusters of augmented quanti
clusts2 = lapply(1:2, function(i){samp_dir[kk2$cluster == i,]})
clusts2 = lapply(clusts2, function(x){x[order(x[,1]),]}) #clusters of kmeans

func_clust = function(list_clusts){ #function that builds a dataframe indicating the cluster associated to each element
  df = data.frame()
  list_clusts = list_clusts[order(sapply(list_clusts, length))]
  for(i in 1:length(list_clusts)){
    df = rbind(df, cbind(list_clusts[[i]], i))
  }
  df[,3] = as.factor(df[,3])
  colnames(df) = c("X","Y","Cluster")
  return(df)
}

f1 = func_clust(clusts1)
f2 = func_clust(clusts2)

plot1 = ggplot() + geom_point(data = f1,aes(x=X,y=Y, col = Cluster)) + geom_point(data = centro1, aes(x = X1, y = X2), shape = 4, size = 4) + theme_bw() + theme(axis.text.x=element_blank(), axis.text.y=element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank())
plot2 = ggplot() + geom_point(data = f2, aes(x=X,y=Y, col = Cluster))  + geom_point(data = centro2, aes(x = X1, y = X2), shape = 4, size = 4)+ theme_bw() + theme(axis.text.x=element_blank(), axis.text.y=element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank())

do.call("grid.arrange", c(list(plot1, plot2), ncol=2))
```


